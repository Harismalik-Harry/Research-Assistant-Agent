# ğŸ§‘â€ğŸ”¬ Research Assistant

A **multi-agent research automation system** built with **LangGraph**, **LangChain**, and **Google Gemini**.
This project demonstrates how to combine **memory**, **human-in-the-loop workflows**, and **controllability** to build a customized AI-powered research pipeline.

---

## ğŸš€ Overview

Research often requires analysts to gather information, interview experts, and synthesize findings into reports. This assistant automates much of that process by orchestrating multiple AI agents:

1. **Source Selection** â€“ Choose from web search or Wikipedia.
2. **Planning** â€“ Break a topic into sub-topics with dedicated AI analysts.
3. **Human-in-the-loop** â€“ Refine and approve sub-topics before research begins.
4. **Multi-turn Interviews** â€“ Analysts interview AI experts in a structured conversation.
5. **Parallel Research** â€“ Interviews and document retrieval happen simultaneously.
6. **Report Writing** â€“ Sections are compiled, then combined into a structured report with an introduction and conclusion.

---

## âœ¨ Features

* ğŸ” Web & Wikipedia search integration (Tavily + LangChain loaders)
* ğŸ§© Modular LangGraph sub-graphs for interviews
* ğŸ‘©â€ğŸ’» Human-in-the-loop feedback before interviews
* ğŸ“ Automatic section and report writing
* ğŸ§  Uses **Gemini 2.5 Pro** as the LLM
* âš¡ Parallel execution with `map-reduce`

---

## ğŸ“‚ Project Structure

```
research-assistant/
â”œâ”€â”€ main.py              # Core research graph orchestration
â”œâ”€â”€ schemas.py           # Pydantic models for structured outputs
â”œâ”€â”€ states.py            # State definitions for LangGraph
â”œâ”€â”€ prompts.py           # Instruction templates for analysts & experts
â”œâ”€â”€ output.jpeg          # Workflow diagram image
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ› ï¸ Tech Stack

* [LangGraph](https://github.com/langchain-ai/langgraph) â€“ stateful multi-agent orchestration
* [LangChain](https://www.langchain.com/) â€“ LLM tooling
* [Google Gemini](https://ai.google/) â€“ chat model for reasoning & writing
* [Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search) â€“ web search integration
* [WikipediaLoader](https://python.langchain.com/docs/integrations/document_loaders/wikipedia) â€“ document loader

---

## âš™ï¸ Installation

```bash
# clone the repository
git clone https://github.com/your-username/research-assistant.git
cd research-assistant

# create virtual environment
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows

# install dependencies
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

```python
from main import graph

# run the research pipeline
topic = "Future of Renewable Energy"
config = {"topic": topic, "max_analysts": 3}

for step in graph.stream(config):
    print(step)
```

---

## ğŸ“Š Workflow

![Research Assistant Workflow](./output.jpeg)

---

## ğŸ“Œ Example Output

* Introduction
* Insights from each sub-topic interview
* Conclusion
* Sources


